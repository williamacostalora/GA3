---
title: "Your Title"
subtitle: "STAT 253: Statistical Machine Learning"
date: today
author: "Your Names"
format:
  html:
    toc: true
    toc-depth: 3
    embed-resources: true
    code-tools: true
---


<!-- Your report should follow the format specified in the Group Assignment 3 Instructions. Please review that document carefully! -->





```{r}
#| include: false
# Load packages 
library(tidyverse)
library(tidymodels)
library(cluster)      # to build the hierarchical clustering algorithm
library(factoextra)
library(reshape2)

```


# Research Goals



# Data

```{r}
#| message: false
#| warning: false
#| include: false

# read in data
music <- read.csv("https://bcheggeseth.github.io/253_spring_2024/data/billboard.csv")

# Check out artists with at least 40 songs
music %>% 
  count(performer) %>% 
  filter(n >= 40) %>% 
  select(performer)

# Pick just one of these artists to study
my_artist <- music %>% 
  filter(performer == "Glee Cast") %>% 
  select(-performer) %>% 
  group_by(song) %>%       # The last rows deal w songs that appear more than once
  slice_sample(n = 1) %>% 
  ungroup()

my_artist <- my_artist %>% 
  column_to_rownames("song")

my_artist %>% 
  mutate(mode = as.factor(mode)) %>%
  mutate(key = as.factor(key)) %>%
  mutate(time_signature = as.factor(time_signature))


```

```{r}
#| message: false
#| warning: false
#| echo: false

# visualization

```


# Cluster Analysis

## Implementation

(Describe methods here.)


We selected hierarchical clustering with complete linkage for this analysis because:

1. Mixed data types: The dataset contains both continuous variables (duration_ms, danceability, energy, etc.) and categorical variables (mode, key, time_signature). Hierarchical clustering with the Gower distance metric effectively handles this mixture by computing appropriate distances for each variable type.

2. Exploratory flexibility: Hierarchical clustering doesn't require specifying the number of clusters upfront, allowing us to explore the dendrogram and use data-driven methods to determine the optimal k.

3. Complete linkage: We chose complete linkage because it measures the maximum distance between points in different clusters, which tends to produce more compact, well-separated clusters. This is particularly useful for identifying distinct song profiles where we want clear boundaries between cluster types.


To determine the optimal number of clusters, we used the elbow method:

The elbow on the curve appears around k = 4 where the curve starts to flatten out significantly. There are sharp drops from k=1 to k=3, but after k=4, the improvements become much smaller and the curve levels off. This indicates that k=4 captures most of the meaningful structure in the data, and adding more clusters beyond this point doesn't substantially improve the clustering quality.


<!-- don't modify the formatting below here -->
See code below for full details.

<details>
<summary>View Code</summary>

```{r}
#| message: false
#| warning: false

# Include all clustering code in here.
# Make sure to include comments explaining what your code does.
# Scenario 2: AT LEAST 1 feature x is a FACTOR (categorical)
# Use either a "complete", "single", "average", or "centroid" linkage
hier_model <- hclust(daisy(my_artist, metric = "gower"), method = "complete")

# Heat maps: ordered by the id variable (not clustering)
heatmap(scale(data.matrix(my_artist)), Colv = NA, Rowv = NA)

# Heat maps: ordered by dendrogram / clustering
heatmap(scale(data.matrix(my_artist)), Colv = NA)

# Build hierarchical clustering model using Gower distance
# Gower distance handles mixed data types (numeric + categorical)
hier_model <- hclust(daisy(my_artist, metric = "gower"), method = "complete")

# Visualize the full dendrogram
fviz_dend(hier_model, cex = 0.5, main = "Complete Dendrogram of Glee Cast Songs")

# Calculate total within-cluster sum of squares for k=1 to 10
# Using cutree to cut the hierarchical tree at different heights
ss_data <- tibble(k = 1:10) %>%
  mutate(tot_withinss = map_dbl(k, ~ {
    # Cut tree at k clusters
    clusters <- cutree(hier_model, k = .x)
    # Calculate distances
    dist_matrix <- daisy(my_artist, metric = "gower")
    # Calculate total within-cluster sum of squares
    sum(sapply(unique(clusters), function(cluster) {
      cluster_points <- which(clusters == cluster)
      if(length(cluster_points) > 1) {
        cluster_dist <- as.matrix(dist_matrix)[cluster_points, cluster_points]
        sum(cluster_dist^2) / (2 * length(cluster_points))
      } else {
        0
      }
    }))
  }))

# Plot the elbow curve
ggplot(ss_data, aes(x = k, y = tot_withinss)) +
  geom_line() +
  geom_point(size = 3) +
  labs(title = "Total Within-Cluster Sum of Squares by K",
       x = "Number of Clusters (k)",
       y = "Total Within-Cluster Sum of Squares") +
  theme_minimal()

# Create final clustering with k=4
cluster_data <- my_artist %>% 
  mutate(cluster = as.factor(cutree(hier_model, k = 4)))

# Visualize clusters on dendrogram
fviz_dend(hier_model, k = 4, cex = 0.35, 
          main = "Dendrogram with 4 Clusters Highlighted",
          palette = "jco")

# Check cluster sizes
cluster_sizes <- cluster_data %>% 
  count(cluster) %>%
  arrange(desc(n))

print(cluster_sizes)

```

</details>




## Insights

The hierarchical clustering of the 181 Glee Cast songs identified four musical profiles.

Cluster 1 (pink, largest group) represents mainstream pop songs with moderate energy (0.67) and danceability (0.56). Looking at the energy vs danceability plot, these songs are spread across the middle range, showing variety within popular music. The valence vs acousticness plot shows these songs have moderate positivity (0.51) with low acousticness (0.22), indicating produced, studio-polished tracks. Duration centers around 3.5 minutes, typical of radio-friendly pop songs.

Cluster 2 (green, second largest) contains high-energy performances with the strongest danceability (0.65) and highest energy (0.85). The scatter plots show these songs clustered in the upper-right, indicating upbeat, energetic tracks. These songs have elevated valence (0.63), making them the most positive-sounding cluster. The bar chart shows low acousticness (0.12) and moderate speechiness (0.08), suggesting electronic production with some rhythmic vocal elements.

Cluster 3 (blue, medium-sized) features longer songs with the widest duration range (3.5-4.5 minutes) as shown in the boxplot. The energy vs danceability plot shows these songs scattered across moderate ranges (energy ~0.39, danceability ~0.38). The acousticness is notably higher (0.49) compared to other clusters, and valence varies widely, indicating emotional diversity in this group.

Cluster 4 (purple, smallest group) stands out with the lowest energy (0.24) and highest acousticness (0.86) visible in the bar chart. The scatter plots show these songs clustered in the lower-left corner of the energy-danceability space, with highly variable valence (0.29). The duration plot reveals this cluster has the most variable song lengths, ranging from 2 to 3.5 minutes, suggesting diverse performance types.

The four clusters reveal distinct musical approaches: energetic dance tracks (Cluster 2), mainstream pop variety (Cluster 1), moderate-energy diverse songs (Cluster 3), and intimate low-energy performances (Cluster 4).

```{r}
#| echo: false
# Visualization 1: Cluster characteristics across key audio features
cluster_summary <- cluster_data %>%
  group_by(cluster) %>%
  summarise(
    avg_energy = mean(energy),
    avg_danceability = mean(danceability),
    avg_valence = mean(valence),
    avg_acousticness = mean(acousticness),
    avg_speechiness = mean(speechiness),
    count = n()
  ) %>%
  pivot_longer(cols = starts_with("avg_"), 
               names_to = "feature", 
               values_to = "value") %>%
  mutate(feature = str_remove(feature, "avg_"))

ggplot(cluster_summary, aes(x = feature, y = value, fill = cluster)) +
  geom_col(position = "dodge") +
  labs(title = "Average Audio Feature Values by Cluster",
       subtitle = "Comparing musical characteristics across the 4 identified clusters",
       x = "Audio Feature",
       y = "Average Value",
       fill = "Cluster") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))



# Visualization 2: Energy vs Danceability scatter plot
ggplot(cluster_data, aes(x = danceability, y = energy, color = cluster, size = valence)) +
  geom_point(alpha = 0.6) +
  labs(title = "Song Clusters: Energy vs Danceability",
       subtitle = "Clear separation between high-energy dance tracks, pop anthems, and mellow ballads",
       x = "Danceability",
       y = "Energy",
       color = "Cluster",
       size = "Valence") +
  theme_minimal()


# Visualization 3: Valence vs Acousticness
ggplot(cluster_data, aes(x = acousticness, y = valence, color = cluster)) +
  geom_point(alpha = 0.6, size = 3) +
  labs(title = "Emotional Tone: Valence vs Acousticness by Cluster",
       subtitle = "Ballads show lower valence with higher acousticness, while dance tracks are upbeat",
       x = "Acousticness",
       y = "Valence (Musical Positivity)",
       color = "Cluster") +
  theme_minimal()

# Visualization 4: Duration distribution by cluster
ggplot(cluster_data, aes(x = cluster, y = duration_ms/60000, fill = cluster)) +
  geom_boxplot(alpha = 0.7) +
  geom_jitter(width = 0.2, alpha = 0.3) +
  labs(title = "Song Duration Distribution by Cluster",
       subtitle = "Cluster 4 shows greater variability, including extended theatrical performances",
       x = "Cluster",
       y = "Duration (minutes)",
       fill = "Cluster") +
  theme_minimal()

```






# Dimension Reduction

## Implementation

(Describe methods here.)

PCA is a tool that helps simplify a big list of song characteristics by turning them into a few main themes or patterns. Instead of looking at every feature separately, like danceability, energy, loudness, and acousticness, PCA groups related features together into new combined categories.

Each of these new categories is called a principal component. The first one (PC1) represents the strongest overall pattern in the songs. The second one (PC2) represents the next most important pattern, and each one after that captures a smaller part of what makes the songs different from each other.

The code below shows how strongly each song characteristic contributes to each principal component, and the percentage of the difference between the songs that is explained by each principal component.


<!-- don't modify the formatting below here -->
See code below for full details.

<details>
<summary>View Code</summary>

```{r}
#| message: false
#| warning: false

# Include all dimension reduction code in here.
# Make sure to include comments explaining what your code does.

# scale = TRUE, center = TRUE first standardizes the features
pca_results <- prcomp(my_artist, scale = TRUE, center = TRUE)

# Get the loadings which define the PCs
pca_results %>% 
  pluck("rotation")

#Measure information captured by each PC
pca_results %>% 
  tidy(matrix = "eigenvalues")

```

</details>



## Insights

(Describe takeaways here.)

Visualization 1 below shows in detail how much of each variable is used in PC1 through PC5. Below are explanations of the first 2 PCs.

PC1: separates songs based on how energetic and “produced” they sound (Energy vs. Acousticness). On the higher side of PC1 we see songs with high danceability, energy, loudness, valence. On the negative side of PC1 we see songs that are  quieter, more acoustic, more speech-like or instrumental.PC1 basically captures the difference between high-energy pop numbers and softer, more acoustic songs in the Glee Cast catalog.

PC2: separates songs based on how well the songs performed commercially. Songs that spent more weeks on the Billboard charts or have higher Spotify popularity end up higher on PC2. PC2 basically distinguishes between songs that were super successfull and popular from those that were not as much of a hit.


PC1 explains about 25% of all the differences between songs (variance), and PC2 explains about 10%. The next three components each add small chunks of information (7-9%). After the PC5, the remaining components contribute very little additional information while making the analysis even more complex by adding extra dimensions. While the largest drop in importance occurs after the first two components, as seen in Visualization 2, we decided to keep five PCs because they provide a more complete picture of how the songs differ from one another. Including five components makes the analysis a bit more complicated, but it allows us to retain more information of the meaningful musical variation in the data.

By keeping five principal components, we keep about 60% of all the information in the original data, as seen in Visualization 3. This means we’re still capturing most of the major musical patterns, such as energy level, acousticness, popularity, and other qualities, while reducing the dataset from 15 separate features down to just 5 summarized dimensions.


```{r}
#| echo: false
# put code for visualizations 
# Load package for tidy table

# PCA Visualization 1: Plotting loadings for first 5 PCs
melt(pca_results$rotation[, 1:5]) %>% 
  ggplot(aes(x = Var1, y = value, fill = Var1)) +
    geom_bar(stat = "identity") +
    facet_wrap(~ Var2) + 
    labs(y = "loadings", x = "original features", fill = "original features")+
    theme(axis.text.x  = element_text(size = 7, angle = 45, hjust = 1) )


# PCA Visualization 2: Scree Plot (% of variance explained by each PC)
pca_results %>% 
  tidy(matrix = "eigenvalues") %>% 
  ggplot(aes(y = percent, x = PC)) + 
    geom_point(size = 2) + 
    geom_line() + 
    labs(y = "% of variance explained")


# PCA Visualization 3: Cumulative % of variance explained by each PC
pca_results %>% 
  tidy(matrix = "eigenvalues") %>% 
  rbind(0) %>% 
  ggplot(aes(y = cumulative, x = PC)) + 
    geom_point(size = 2) + 
    geom_line() + 
    labs(y = "CUMULATIVE % of variance explained")

```



# Conclusion





# Contributions






# Appendix

```{r}
#| eval: false
# put code for any other methods or visualizations that you considered here
# use comments to explain what your code is doing
```

